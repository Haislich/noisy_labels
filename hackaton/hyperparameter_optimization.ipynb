{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lAQuCuIoBbq5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from functools import partial\n",
    "import optuna\n",
    "import gc\n",
    "from typing import Literal\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch_geometric.data import Batch\n",
    "from torch.utils.data import Subset, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Load utility functions from cloned repository\n",
    "from src.loadData import GraphDataset\n",
    "from src.utils import set_seed\n",
    "from src.models import GNN\n",
    "\n",
    "\n",
    "# Set the random seed\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Dyf0I2-t9IcW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_zeros(data):\n",
    "    data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WanuZKxy9Zs-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_predictions(predictions, test_path):\n",
    "    script_dir = os.getcwd()\n",
    "    submission_folder = os.path.join(script_dir, \"submission\")\n",
    "    test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
    "\n",
    "    os.makedirs(submission_folder, exist_ok=True)\n",
    "\n",
    "    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
    "\n",
    "    test_graph_ids = list(range(len(predictions)))\n",
    "    output_df = pd.DataFrame({\"id\": test_graph_ids, \"pred\": predictions})\n",
    "\n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predictions saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uyHIJS5U9ZzB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_progress(train_losses, train_accuracies, output_dir):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\", color=\"blue\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss per Epoch\")\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color=\"green\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training Accuracy per Epoch\")\n",
    "\n",
    "    # Save plots in the current directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NoisyCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self, p_noisy):\n",
    "        super().__init__()\n",
    "        self.p = p_noisy\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        losses = self.ce(logits, targets)\n",
    "        weights = (1 - self.p) + self.p * (\n",
    "            1\n",
    "            - torch.nn.functional.one_hot(targets, num_classes=logits.size(1))\n",
    "            .float()\n",
    "            .sum(dim=1)\n",
    "        )\n",
    "        return (losses * weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCELoss(torch.nn.Module):\n",
    "    def __init__(self, num_classes: int = 6, alpha: float = 0.1, beta: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.alpha, self.beta = alpha, beta\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # CCE\n",
    "        ce = F.cross_entropy(logits, targets, reduction=\"none\")\n",
    "\n",
    "        # RCE\n",
    "        pred = F.softmax(logits, dim=1).clamp(min=1e-6, max=1 - 1e-6)\n",
    "        one_hot = F.one_hot(targets, self.num_classes).float()\n",
    "        rce = -(1 - one_hot) * torch.log(1 - pred)\n",
    "        rce = rce.sum(dim=1)\n",
    "        return (self.alpha * ce + self.beta * rce).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCODLoss(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        embedding_dimensions: int = 300,\n",
    "        total_epochs: int = 150,\n",
    "        lambda_consistency: float = 1.0,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.device = device\n",
    "        self.embedding_dimensions = embedding_dimensions\n",
    "        self.total_epochs = total_epochs\n",
    "        self.lambda_consistency = lambda_consistency\n",
    "\n",
    "        label_counts = {}\n",
    "        for elem in dataset:\n",
    "            y = int(elem.y)\n",
    "            label_counts[y] = label_counts.get(y, 0) + 1\n",
    "\n",
    "        self.num_elements = len(dataset)\n",
    "        self.num_classes = len(label_counts)\n",
    "\n",
    "        self.u = nn.Parameter(torch.empty(self.num_elements, 1, device=device))\n",
    "        torch.nn.init.normal_(self.u, mean=1e-8, std=1e-9)\n",
    "\n",
    "        self.past_embeddings = torch.rand(\n",
    "            (self.num_elements, embedding_dimensions), device=device\n",
    "        )\n",
    "        self.centroids = torch.rand(\n",
    "            (self.num_classes, embedding_dimensions), device=device\n",
    "        )\n",
    "\n",
    "        self.bins = [[] for _ in range(self.num_classes)]\n",
    "        for idx, d in enumerate(dataset):\n",
    "            self.bins[int(d.y)].append(idx)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        logits: torch.Tensor,     \n",
    "        indexes: torch.Tensor,      \n",
    "        embeddings: torch.Tensor,   \n",
    "        targets: torch.Tensor,      \n",
    "        epoch: int,\n",
    "    ):\n",
    "        eps = 1e-6\n",
    "        device = logits.device\n",
    "\n",
    "        embeddings = F.normalize(embeddings, dim=1)\n",
    "        self.past_embeddings[indexes] = embeddings.detach()\n",
    "\n",
    "        if epoch == 0:\n",
    "            with torch.no_grad():\n",
    "                for c in range(self.num_classes):\n",
    "                    idxs = self.bins[c]\n",
    "                    if idxs:\n",
    "                        self.centroids[c] = self.past_embeddings[idxs].mean(0)\n",
    "        else:\n",
    "            percent = math.ceil((50 - (50 / self.total_epochs) * epoch) + 50)\n",
    "            for c in range(self.num_classes):\n",
    "                idxs = self.bins[c]\n",
    "                if not idxs:\n",
    "                    continue\n",
    "                u_vals = self.u[idxs]\n",
    "                k = int(len(u_vals) * percent / 100)\n",
    "                keep = torch.topk(u_vals.squeeze(), k, largest=False).indices\n",
    "                self.centroids[c] = self.past_embeddings[[idxs[i] for i in keep]].mean(0)\n",
    "\n",
    "        cent = F.normalize(self.centroids, dim=1)\n",
    "        cosine_sim = embeddings @ cent.T                      \n",
    "        soft_labels = F.softmax(cosine_sim, dim=1)           \n",
    "\n",
    "        # ---- prediction adjustment ---------------------------------\n",
    "        probs = F.softmax(logits, dim=1)                      # [B, C]\n",
    "        u_vals = torch.sigmoid(self.u[indexes]).squeeze(1)    # (0,1)\n",
    "        adjusted_probs = probs + u_vals.unsqueeze(1) * soft_labels\n",
    "        adjusted_probs = adjusted_probs.clamp(min=eps)\n",
    "        adjusted_probs = adjusted_probs / adjusted_probs.sum(1, keepdim=True)\n",
    "\n",
    "        # ---- losses -------------------------------------------------\n",
    "        # 1. discounted hard CE\n",
    "        hard_ce = F.cross_entropy(logits, targets, reduction='none')\n",
    "        hard_ce = ((1.0 - u_vals) * hard_ce).mean()\n",
    "\n",
    "        # 2. soft-label CE (only on the target column, as in the paper)\n",
    "        tgt_onehot = F.one_hot(targets, num_classes=self.num_classes).float()\n",
    "        soft_loss = -torch.sum(\n",
    "            (tgt_onehot * soft_labels) * torch.log(adjusted_probs),\n",
    "            dim=1\n",
    "        ).mean()\n",
    "\n",
    "        # 3. consistency\n",
    "        loss_cons = F.mse_loss(adjusted_probs, soft_labels)\n",
    "\n",
    "        return hard_ce + soft_loss + self.lambda_consistency * loss_cons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jKvoQYI9Zbc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    data_loader,\n",
    "    model,\n",
    "    optimizer_theta,\n",
    "    optimizer_u,\n",
    "    criterion,          # may be NCODLoss\n",
    "    device,\n",
    "    save_checkpoints,\n",
    "    checkpoint_path,\n",
    "    current_epoch=0,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = total_conf = total_entropy = 0.0\n",
    "    correct = total = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        node_emb = model.gnn_node(data)\n",
    "        graph_emb = model.pool(node_emb, data.batch)\n",
    "        logits = model.graph_pred_linear(graph_emb)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        optimizer_theta.zero_grad()\n",
    "        optimizer_u.zero_grad()\n",
    "        if isinstance(criterion, NCODLoss):\n",
    "            \n",
    "            loss = criterion(\n",
    "                logits=logits,\n",
    "                indexes=data.idx.to(device),\n",
    "                embeddings=graph_emb,\n",
    "                targets=data.y.to(device),\n",
    "                epoch=current_epoch,\n",
    "            )\n",
    "        else:\n",
    "            loss = criterion(logits, data.y)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_theta.step()\n",
    "        optimizer_u.step()\n",
    "        \n",
    "\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = probs.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "        total_conf += probs.max(1).values.sum().item()\n",
    "        total_entropy += (-torch.sum(probs * torch.log(probs + 1e-10), 1)).sum().item()\n",
    "\n",
    "    \n",
    "    if save_checkpoints:\n",
    "        ckpt_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), ckpt_file)\n",
    "        print(f\"[checkpoint] saved: {ckpt_file}\")\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_conf = total_conf / total\n",
    "    avg_entropy = total_entropy / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, avg_conf, accuracy, avg_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8peFiIS19ZpK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    data_loader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_confidence = 0.0\n",
    "    total_entropy = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            node_emb = model.gnn_node(data)\n",
    "            graph_emb = model.pool(node_emb, data.batch)\n",
    "            logits = model.graph_pred_linear(graph_emb)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "            # Compute loss (match train logic)\n",
    "            if isinstance(criterion, NCODLoss):\n",
    "                indexes = (\n",
    "                    data.idx\n",
    "                    if hasattr(data, \"idx\")\n",
    "                    else torch.arange(total, total + logits.size(0))\n",
    "                )\n",
    "                loss = criterion(\n",
    "                    logits=logits,\n",
    "                    indexes=indexes.to(device),\n",
    "                    embeddings=graph_emb,\n",
    "                    epoch=-1,\n",
    "                )\n",
    "            else:\n",
    "                loss = criterion(logits, data.y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Metrics\n",
    "            pred = probs.argmax(dim=1)\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "\n",
    "            total_confidence += probs.max(dim=1).values.sum().item()\n",
    "            total_entropy += (\n",
    "                (-torch.sum(probs * torch.log(probs + 1e-10), dim=1)).sum().item()\n",
    "            )\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_conf = total_confidence / total\n",
    "    avg_entropy = total_entropy / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return (\n",
    "        avg_loss,\n",
    "        avg_conf,\n",
    "        accuracy,\n",
    "        avg_entropy,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(data_loader, model, device, criterion=None):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     total_loss = 0.0\n",
    "#     total_confidence = 0.0\n",
    "#     total_entropy = 0.0\n",
    "#     predictions = []\n",
    "\n",
    "#     use_ce_loss = isinstance(criterion, torch.nn.CrossEntropyLoss)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for data in data_loader:\n",
    "#             data = data.to(device)\n",
    "\n",
    "#             # Forward\n",
    "#             node_emb = model.gnn_node(data)\n",
    "#             graph_emb = model.pool(node_emb, data.batch)\n",
    "#             logits = model.graph_pred_linear(graph_emb)\n",
    "#             probs = F.softmax(logits, dim=1)\n",
    "\n",
    "#             pred = probs.argmax(dim=1)\n",
    "#             predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "#             if calculate_accuracy:\n",
    "#                 correct += (pred == data.y).sum().item()\n",
    "#                 total += data.y.size(0)\n",
    "\n",
    "#                 if use_ce_loss:\n",
    "#                     total_loss += criterion(logits, data.y).item()\n",
    "\n",
    "#             # Confidence = max prob\n",
    "#             total_confidence += probs.max(dim=1).values.sum().item()\n",
    "\n",
    "#             # Entropy = -∑p log p\n",
    "#             entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=1)  # [B]\n",
    "#             total_entropy += entropy.sum().item()\n",
    "\n",
    "#     if calculate_accuracy:\n",
    "#         accuracy = correct / total if total > 0 else 0.0\n",
    "#         avg_loss = total_loss / len(data_loader) if use_ce_loss else None\n",
    "#         avg_conf = total_confidence / total\n",
    "#         avg_entropy = total_entropy / total\n",
    "\n",
    "#         return {\n",
    "#             \"accuracy\": accuracy,\n",
    "#             \"cross_entropy_loss\": avg_loss,\n",
    "#             \"avg_confidence\": avg_conf,\n",
    "#             \"avg_entropy\": avg_entropy,\n",
    "#         }\n",
    "\n",
    "#     return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(\n",
    "    trial,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_checkpoints,\n",
    "    checkpoints_dir,\n",
    "    run_name,\n",
    "    best_model_path,\n",
    "    logs_dir,\n",
    "    *,\n",
    "    score_type: Literal[\"loss\", \"accuracy\", \"entropy\", \"confidence\"] = \"confidence\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "):  # -> float | Any:\n",
    "    logging.info(\"#\" * 80)\n",
    "    # Hyperparameter search space\n",
    "    logging.info(\"Start case study with parameters:\")\n",
    "    gnn_type = \"gin-virtual\"\n",
    "    # trial.suggest_categorical(\n",
    "    #     \"gnn_type\", [\"gin\", ]\n",
    "    # )\n",
    "    drop_ratio = 0.0  # trial.suggest_float(\"dropout\", 0.0, 0.7)\n",
    "    num_layers = 5  # trial.suggest_int(\"num_layers\", 6, 12)\n",
    "    embedding_dim = 300  # trial.suggest_categorical(\"embedding_dim\", [64, 128, 300])\n",
    "    num_epochs = 60  # trial.suggest_int(\"num_epochs\", 10, 11, step=1)\n",
    "\n",
    "    logging.info(f\"{gnn_type=}\")\n",
    "    logging.info(f\"{drop_ratio=}\")\n",
    "    logging.info(f\"{num_layers=}\")\n",
    "    logging.info(f\"{embedding_dim=}\")\n",
    "    logging.info(f\"{num_epochs=}\")\n",
    "\n",
    "    # Initialize model\n",
    "    model = GNN(\n",
    "        gnn_type=\"gin\" if \"gin\" in gnn_type else \"gcn\",\n",
    "        num_class=6,\n",
    "        num_layer=num_layers,\n",
    "        emb_dim=embedding_dim,\n",
    "        drop_ratio=drop_ratio,\n",
    "        virtual_node=\"virtual\" in gnn_type,\n",
    "    ).to(device)\n",
    "    # NCOD by default — switch to CE for testing if needed\n",
    "    criterion = NCODLoss(\n",
    "        train_loader.dataset,\n",
    "        embedding_dimensions=embedding_dim,\n",
    "        total_epochs=num_epochs,\n",
    "    ).to(device)\n",
    "    optimizer_theta = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "    optimizer_u     = torch.optim.SGD(criterion.parameters(), lr=1e-3)\n",
    "\n",
    "    # Checkpoint logic\n",
    "    checkpoint_epochs = [\n",
    "        int((i + 1) * num_epochs / num_checkpoints) for i in range(num_checkpoints)\n",
    "    ]\n",
    "\n",
    "    best_val_score = -float(\"inf\")\n",
    "    train_losses, train_confs, train_accs, train_entropies, train_scores = (\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    )\n",
    "    val_losses, val_confs, val_accs, val_entropies, val_scores = [], [], [], [], []\n",
    "\n",
    "    progress_bar = tqdm(range(num_epochs), desc=\"Training...\", leave=False)\n",
    "    for epoch in progress_bar:\n",
    "        train_loss, train_conf, train_acc, train_entropy = train(\n",
    "            train_loader,\n",
    "            model,\n",
    "            optimizer_theta,\n",
    "            optimizer_u,\n",
    "            criterion,\n",
    "            device,\n",
    "            save_checkpoints=(epoch + 1 in checkpoint_epochs),\n",
    "            checkpoint_path=os.path.join(checkpoints_dir, f\"model_{run_name}\"),\n",
    "            current_epoch=epoch,\n",
    "        )\n",
    "\n",
    "        val_loss, val_conf, val_acc, val_entropy = evaluate(\n",
    "            val_loader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "        \n",
    "        tqdm.write(\n",
    "            f\"Epoch {epoch}/{num_epochs}\\n\"\n",
    "            f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Conf: {train_conf:.4f}, Entropy: {train_entropy:.4f}\\n\"\n",
    "            f\"Val Loss  : {val_loss:.4f}, Acc: {val_acc:.4f}, Conf: {val_conf:.4f}, Entropy: {val_entropy:.4f}\\n\"\n",
    "        \n",
    "        )\n",
    "        logging.info(\n",
    "            f\"Epoch {epoch}/{num_epochs}\\n\"\n",
    "            f\"\\tTrain Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Conf: {train_conf:.4f}, Entropy: {train_entropy:.4f}\\n\"\n",
    "            f\"\\tVal Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Conf: {val_conf:.4f}, Entropy: {val_entropy:.4f}\\n\"\n",
    "        )\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        train_confs.append(train_conf)\n",
    "        train_entropies.append(train_entropy)\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_confs.append(val_conf)\n",
    "        val_entropies.append(val_entropy)\n",
    "\n",
    "        if score_type == \"loss\":\n",
    "            train_score = train_loss\n",
    "            val_score = val_loss\n",
    "        elif score_type == \"entropy\":\n",
    "            train_score = train_entropy\n",
    "            val_score = val_entropy\n",
    "        elif score_type == \"confidence\":\n",
    "            train_score = train_conf\n",
    "            val_score = val_conf\n",
    "        else:\n",
    "            train_score = train_acc\n",
    "            val_score = val_acc\n",
    "\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            logging.info(f\"[{run_name}] Best model updated at {best_model_path}\")\n",
    "\n",
    "    # Plot training curves\n",
    "    plot_training_progress(\n",
    "        train_losses, train_scores, os.path.join(logs_dir, \"train_plots\")\n",
    "    )\n",
    "    plot_training_progress(val_losses, val_scores, os.path.join(logs_dir, \"val_plots\"))\n",
    "\n",
    "    logging.info(f\"Case study end, {best_val_score}\")\n",
    "    logging.info(\"#\" * 80)\n",
    "    logging.info(\"\\n\")\n",
    "\n",
    "    return best_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedSubset(Dataset):\n",
    "    def __init__(self, subset: Subset):\n",
    "        self.subset = subset\n",
    "    def __len__(self):  return len(self.subset)\n",
    "    def __getitem__(self, i):\n",
    "        data = self.subset[i]\n",
    "        data.idx = torch.tensor(i, dtype=torch.long)   # permanent id in 0…len-1\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_study(\n",
    "    dataset_name: Literal[\"A\", \"B\", \"C\", \"D\"],\n",
    "    n_trials: int = 30,\n",
    "    num_checkpoints: int = 10,\n",
    "    default_batch_size: int = 32,\n",
    "    score_type: Literal[\"loss\", \"accuracy\", \"entropy\", \"confidence\"] = \"confidence\",\n",
    "    full_dataset=None,\n",
    "):\n",
    "    script_root = os.getcwd()\n",
    "    train_path = f\"./datasets/{dataset_name}/train.json.gz\"\n",
    "    run_name = dataset_name\n",
    "\n",
    "    logs_dir = os.path.join(script_root, \"logs\", run_name)\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n",
    "    logging.basicConfig(\n",
    "        filename=os.path.join(logs_dir, \"training.log\"),\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        filemode=\"w\",\n",
    "    )\n",
    "    # logging.getLogger().addHandler(logging.StreamHandler())\n",
    "\n",
    "    checkpoints_dir = os.path.join(script_root, \"checkpoints\", run_name)\n",
    "    best_model_path = os.path.join(checkpoints_dir, f\"model_{run_name}_best.pth\")\n",
    "    summary_csv_path = os.path.join(logs_dir, f\"optuna_summary_{dataset_name}.csv\")\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    if full_dataset is None:\n",
    "        full_dataset = GraphDataset(train_path, transform=add_zeros)\n",
    "    val_size = int(0.2 * len(full_dataset))\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    generator = torch.Generator().manual_seed(12)\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_dataset, [train_size, val_size], generator=generator\n",
    "    )\n",
    "    train_dataset = IndexedSubset(train_dataset)\n",
    "    val_dataset = IndexedSubset(val_dataset)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,  # type:ignore\n",
    "        batch_size=default_batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,  # type:ignore\n",
    "        batch_size=default_batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    print(f\"Starting Optuna optimization for dataset {dataset_name}\")\n",
    "\n",
    "    study = optuna.create_study(study_name=run_name, direction=\"minimize\" if score_type ==\"loss\" else \"maximize\")\n",
    "\n",
    "    obj = partial(\n",
    "        objective,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_checkpoints=num_checkpoints,\n",
    "        checkpoints_dir=checkpoints_dir,\n",
    "        run_name=run_name,\n",
    "        best_model_path=best_model_path,\n",
    "        logs_dir=logs_dir,\n",
    "        score_type=\"confidence\",\n",
    "    )\n",
    "    study.optimize(obj, n_trials=n_trials)\n",
    "\n",
    "    all_trials = []\n",
    "    for trial in study.trials:\n",
    "        if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "            row = {score_type: trial.value}\n",
    "            row.update(trial.params)\n",
    "            all_trials.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(all_trials)\n",
    "    results_df.to_csv(summary_csv_path, index=False)\n",
    "\n",
    "    print(f\"\\nAll trials saved to: {summary_csv_path}\")\n",
    "    print(f\"\\nBest result for dataset {dataset_name}:\")\n",
    "    display(results_df.sort_values(score_type, ascending=False))\n",
    "    print(f\"\\nBest Params for {dataset_name}:\")\n",
    "    for k, v in study.best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    del train_loader, val_loader, full_dataset, train_dataset, val_dataset\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_a = GraphDataset(\"./datasets/A/train.json.gz\",transform=add_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 16:45:48,557] A new study created in memory with name: A\n",
      "[W 2025-05-26 16:45:48,578] Trial 0 failed with parameters: {} because of the following error: RuntimeError('CUDA error: device-side assert triggered\\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/haislich/Documents/noisy_labels/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3360/2992990716.py\", line 40, in objective\n",
      "    ).to(device)\n",
      "      ^^^^^^^^^^\n",
      "  File \"/home/haislich/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1355, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/haislich/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/haislich/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/haislich/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 942, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/haislich/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1341, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "[W 2025-05-26 16:45:48,579] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna optimization for dataset A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcase_study\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfull_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_a\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# case_study(\"B\", 1)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# case_study(\"C\", 1)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# case_study(\"D\", 1)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mcase_study\u001b[39m\u001b[34m(dataset_name, n_trials, num_checkpoints, default_batch_size, score_type, full_dataset)\u001b[39m\n\u001b[32m     53\u001b[39m study = optuna.create_study(study_name=run_name, direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score_type ==\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m obj = partial(\n\u001b[32m     56\u001b[39m     objective,\n\u001b[32m     57\u001b[39m     train_loader=train_loader,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     score_type=\u001b[33m\"\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m all_trials = []\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m study.trials:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, train_loader, val_loader, num_checkpoints, checkpoints_dir, run_name, best_model_path, logs_dir, score_type, device)\u001b[39m\n\u001b[32m     30\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Initialize model\u001b[39;00m\n\u001b[32m     33\u001b[39m model = \u001b[43mGNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgnn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgnn_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgcn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_class\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43memb_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvirtual_node\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvirtual\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgnn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# NCOD by default — switch to CE for testing if needed\u001b[39;00m\n\u001b[32m     42\u001b[39m criterion = NCODLoss(\n\u001b[32m     43\u001b[39m     train_loader.dataset,\n\u001b[32m     44\u001b[39m     embedding_dimensions=embedding_dim,\n\u001b[32m     45\u001b[39m     total_epochs=num_epochs,\n\u001b[32m     46\u001b[39m ).to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/noisy_labels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "case_study(\"A\", 1,full_dataset = dataset_a) \n",
    "# case_study(\"B\", 1)\n",
    "# case_study(\"C\", 1)\n",
    "# case_study(\"D\", 1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
